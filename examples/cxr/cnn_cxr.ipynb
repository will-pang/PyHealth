{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09bf163",
   "metadata": {},
   "source": [
    "# 1. Environment Setup\n",
    "Seed the random generators, import core dependencies, and detect the training device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cdb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "from pyhealth.datasets import COVID19CXRDataset\n",
    "from pyhealth.datasets.splitter import split_by_sample\n",
    "from pyhealth.datasets.utils import get_dataloader\n",
    "from pyhealth.tasks.covid19_cxr_classification import COVID19CXRClassification\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef621a0",
   "metadata": {},
   "source": [
    "# 2. Load COVID-19 CXR Metadata\n",
    "Point to the processed COVID-19 Radiography dataset root and trigger metadata preparation if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = COVID19CXRDataset(\n",
    "    root=\"/home/logic/Github/cxr\",\n",
    ")\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b498db",
   "metadata": {},
   "source": [
    "# 3. Prepare PyHealth Dataset\n",
    "Instantiate the COVID-19 classification task, convert raw samples into PyHealth format, and confirm schema details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = COVID19CXRClassification()\n",
    "sample_dataset = dataset.set_task(task)\n",
    "\n",
    "print(f\"Total task samples: {len(sample_dataset)}\")\n",
    "print(f\"Input schema: {sample_dataset.input_schema}\")\n",
    "print(f\"Output schema: {sample_dataset.output_schema}\")\n",
    "\n",
    "if len(sample_dataset) == 0:\n",
    "    raise RuntimeError(\"The task did not produce any samples. Verify the dataset root or disable dev mode.\")\n",
    "\n",
    "label_processor = sample_dataset.output_processors[\"disease\"]\n",
    "IDX_TO_LABEL = {index: label for label, index in label_processor.label_vocab.items()}\n",
    "print(f\"Label mapping (index -> name): {IDX_TO_LABEL}\")\n",
    "\n",
    "# Build label histogram to confirm class balance\n",
    "label_indices = [sample_dataset[i][\"disease\"].item() for i in range(len(sample_dataset))]\n",
    "label_distribution = (\n",
    "    pd.Series(label_indices)\n",
    "    .map(IDX_TO_LABEL)\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .to_frame(name=\"count\")\n",
    ")\n",
    "label_distribution[\"proportion\"] = label_distribution[\"count\"] / label_distribution[\"count\"].sum()\n",
    "display(label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e012cb",
   "metadata": {},
   "source": [
    "# 4. Split Dataset\n",
    "Divide the processed samples into training, validation, and test subsets before building dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds, test_ds = split_by_sample(sample_dataset, [0.7, 0.1, 0.2], seed=SEED)\n",
    "print(f\"Train/Val/Test sizes: {len(train_ds)}, {len(val_ds)}, {len(test_ds)}\")\n",
    "\n",
    "train_loader = get_dataloader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val_ds, batch_size=BATCH_SIZE) if len(val_ds) else None\n",
    "test_loader = get_dataloader(test_ds, batch_size=BATCH_SIZE) if len(test_ds) else None\n",
    "\n",
    "if len(train_loader) == 0:\n",
    "    raise RuntimeError(\"The training loader is empty. Increase the dataset size or adjust the split ratios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdadab",
   "metadata": {},
   "source": [
    "# 5. Inspect Batch Structure\n",
    "Peek at the first training batch to understand feature shapes and label encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bdd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "def describe(value):\n",
    "    if hasattr(value, \"shape\"):\n",
    "        return f\"{type(value).__name__}(shape={tuple(value.shape)})\"\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        return f\"{type(value).__name__}(len={len(value)})\"\n",
    "    return type(value).__name__\n",
    "\n",
    "batch_summary = {key: describe(value) for key, value in first_batch.items()}\n",
    "print(batch_summary)\n",
    "\n",
    "disease_targets = first_batch[\"disease\"]\n",
    "preview_indices = disease_targets[:5].cpu().tolist()\n",
    "preview_labels = [IDX_TO_LABEL[idx] for idx in preview_indices]\n",
    "print(f\"Sample disease labels: {list(zip(preview_indices, preview_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0fd406",
   "metadata": {},
   "source": [
    "# 6. Instantiate CNN Model\n",
    "Create the PyHealth CNN with image embeddings and review its parameter footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import CNN\n",
    "\n",
    "model = CNN(\n",
    "    dataset=sample_dataset,\n",
    "    embedding_dim=64,\n",
    "    hidden_dim=64,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Feature keys: {model.feature_keys}\")\n",
    "print(f\"Label key: {model.label_key}\")\n",
    "print(f\"Model mode: {model.mode}\")\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d4a34",
   "metadata": {},
   "source": [
    "# 7. Configure Trainer\n",
    "Wrap the model with the PyHealth Trainer and define optimisation hyperparameters and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    metrics=[\"accuracy\", \"f1_macro\", \"f1_micro\"],\n",
    "    device=str(device),\n",
    "    enable_logging=False,\n",
    " )\n",
    "\n",
    "training_config = {\n",
    "    \"epochs\": 3,\n",
    "    \"optimizer_params\": {\"lr\": 1e-3},\n",
    "    \"max_grad_norm\": 5.0,\n",
    "    \"monitor\": \"accuracy\",\n",
    "    \"monitor_criterion\": \"max\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18480f33",
   "metadata": {},
   "source": [
    "# 8. Train the Model\n",
    "Launch the training loop with optional validation monitoring for early diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = dict(training_config)\n",
    "if val_loader is None:\n",
    "    train_kwargs.pop(\"monitor\", None)\n",
    "    train_kwargs.pop(\"monitor_criterion\", None)\n",
    "\n",
    "trainer.train(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    **train_kwargs,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272fad1",
   "metadata": {},
   "source": [
    "# 9. Evaluate on Validation/Test Splits\n",
    "Compute accuracy and F1 scores on the held-out loaders to assess generalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {}\n",
    "for split_name, loader in {\"validation\": val_loader, \"test\": test_loader}.items():\n",
    "    if loader is None:\n",
    "        continue\n",
    "    metrics = trainer.evaluate(loader)\n",
    "    evaluation_results[split_name] = metrics\n",
    "    formatted = \", \".join(f\"{k}={v:.4f}\" for k, v in metrics.items())\n",
    "    print(f\"{split_name.title()} metrics: {formatted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbfae0",
   "metadata": {},
   "source": [
    "# 10. Inspect Sample Predictions\n",
    "Run an inference pass and preview top predictions alongside their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loader = val_loader if val_loader is not None else train_loader\n",
    "\n",
    "y_true, y_prob, mean_loss = trainer.inference(target_loader)\n",
    "top_indices = y_prob.argmax(axis=-1)\n",
    "preview = []\n",
    "for i, (true_idx, pred_idx) in enumerate(zip(y_true[:5], top_indices[:5])):\n",
    "    prob = float(y_prob[i, pred_idx])\n",
    "    preview.append({\n",
    "        \"true_index\": int(true_idx),\n",
    "        \"true_label\": IDX_TO_LABEL[int(true_idx)],\n",
    "        \"pred_index\": int(pred_idx),\n",
    "        \"pred_label\": IDX_TO_LABEL[int(pred_idx)],\n",
    "        \"pred_prob\": prob,\n",
    "    })\n",
    "\n",
    "print(f\"Mean loss: {mean_loss:.4f}\")\n",
    "for sample in preview:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f9c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
