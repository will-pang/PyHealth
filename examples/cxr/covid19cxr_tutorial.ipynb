{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ad4b00",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c5dddd",
   "metadata": {},
   "source": [
    "## Covid19CXR Comprehensive Tutorial\n",
    "\n",
    "This tutorial takes you from start to finish with the COVID19CXR dataset and explores many post-hoc deployment aspects of PyHealth\n",
    "\n",
    "Namely, we go through:\n",
    "- Loading the data\n",
    "- Training a model\n",
    "- Doing Conformal Prediction\n",
    "- Running Interpretability on Predicted Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyhealth.calib.predictionset import LABEL\n",
    "from pyhealth.datasets import (\n",
    "    COVID19CXRDataset,\n",
    "    get_dataloader,\n",
    "    split_by_sample_conformal,\n",
    ")\n",
    "from pyhealth.models import TorchvisionModel\n",
    "from pyhealth.trainer import Trainer, get_metrics_fn\n",
    "from pyhealth.interpret.methods import CheferRelevance\n",
    "from pyhealth.interpret.utils import visualize_image_attr\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/johnwu3/projects/PyHealth_Branch_Testing/datasets/COVID-19_Radiography_Dataset\"\n",
    "base_cache = \"/home/johnwu3/projects/covid19cxr_base_cache\"\n",
    "task_cache = \"/home/johnwu3/projects/covid19cxr_task_cache\"\n",
    "model_checkpoint = \"/home/johnwu3/projects/covid19cxr_vit_model.ckpt\"\n",
    "\n",
    "base_dataset = COVID19CXRDataset(root, cache_dir=base_cache, num_workers=4)\n",
    "sample_dataset = base_dataset.set_task(cache_dir=task_cache, num_workers=4)\n",
    "\n",
    "print(f\"Total samples: {len(sample_dataset)}\")\n",
    "print(f\"Task mode: {sample_dataset.output_schema}\")\n",
    "\n",
    "# Get class names from dataset processor's label_vocab\n",
    "# label_vocab maps {label_name: index}, we invert it to get {index: label_name}\n",
    "label_vocab = sample_dataset.output_processors[\"disease\"].label_vocab\n",
    "id2label = {idx: label for label, idx in label_vocab.items()}\n",
    "print(f\"Classes: {list(id2label.values())}\")\n",
    "\n",
    "# Split into train/val/cal/test\n",
    "train_data, val_data, cal_data, test_data = split_by_sample_conformal(\n",
    "    dataset=sample_dataset, ratios=[0.6, 0.1, 0.15, 0.15]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_data)}\")\n",
    "print(f\"Val: {len(val_data)}\")\n",
    "print(f\"Cal: {len(cal_data)} (for conformal calibration)\")\n",
    "print(f\"Test: {len(test_data)}\")\n",
    "\n",
    "# Create data loaders (batch_size=64 for better GPU utilization)\n",
    "train_loader = get_dataloader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = get_dataloader(val_data, batch_size=64, shuffle=False)\n",
    "cal_loader = get_dataloader(cal_data, batch_size=64, shuffle=False)\n",
    "test_loader = get_dataloader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ce1b5",
   "metadata": {},
   "source": [
    "### Dataloading/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48824d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total samples: {len(sample_dataset)}\")\n",
    "print(f\"Task mode: {sample_dataset.output_schema}\")\n",
    "\n",
    "# Get class names from dataset processor's label_vocab\n",
    "# label_vocab maps {label_name: index}, we invert it to get {index: label_name}\n",
    "label_vocab = sample_dataset.output_processors[\"disease\"].label_vocab\n",
    "id2label = {idx: label for label, idx in label_vocab.items()}\n",
    "print(f\"Classes: {list(id2label.values())}\")\n",
    "\n",
    "# Split into train/val/cal/test\n",
    "train_data, val_data, cal_data, test_data = split_by_sample_conformal(\n",
    "    dataset=sample_dataset, ratios=[0.6, 0.1, 0.15, 0.15]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_data)}\")\n",
    "print(f\"Val: {len(val_data)}\")\n",
    "print(f\"Cal: {len(cal_data)} (for conformal calibration)\")\n",
    "print(f\"Test: {len(test_data)}\")\n",
    "\n",
    "# Create data loaders (batch_size=64 for better GPU utilization)\n",
    "train_loader = get_dataloader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = get_dataloader(val_data, batch_size=64, shuffle=False)\n",
    "cal_loader = get_dataloader(cal_data, batch_size=64, shuffle=False)\n",
    "test_loader = get_dataloader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0cddf",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: Vision Transformer (ViT) Model\")\n",
    "print(\"=\" * 80)\n",
    "# Initialize ViT with pretrained weights\n",
    "model = TorchvisionModel(\n",
    "    dataset=sample_dataset,\n",
    "    model_name=\"vit_b_16\",  # Vision Transformer Base with patch size 16\n",
    "    model_config={\"weights\": \"DEFAULT\"},\n",
    ")\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check if saved model exists\n",
    "if os.path.exists(model_checkpoint):\n",
    "    print(f\"Found saved model at {model_checkpoint}\")\n",
    "    print(\"Loading model from checkpoint...\")\n",
    "    trainer = Trainer(model=model, device=device, checkpoint_path=model_checkpoint)\n",
    "    print(\"✓ Model loaded from checkpoint\")\n",
    "else:\n",
    "    print(f\"No saved model found at {model_checkpoint}\")\n",
    "    print(\"Training new model...\")\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "\n",
    "    print(f\"Training on device: {device}\")\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=50,\n",
    "        monitor=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    print(f\"Saving model to {model_checkpoint}...\")\n",
    "    trainer.save_ckpt(model_checkpoint)\n",
    "    print(\"✓ Model training completed and saved\")\n",
    "\n",
    "# Evaluate base model on test set\n",
    "print(\"\\nBase model performance on test set:\")\n",
    "y_true_base, y_prob_base, loss_base = trainer.inference(test_loader)\n",
    "base_metrics = get_metrics_fn(\"multiclass\")(\n",
    "    y_true_base, y_prob_base, metrics=[\"accuracy\", \"f1_weighted\"]\n",
    ")\n",
    "for metric, value in base_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0200302",
   "metadata": {},
   "source": [
    "## Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Conformal Prediction with LABEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: Conformal Prediction with LABEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Target miscoverage rate of 10% (90% coverage)\n",
    "alpha = 0.1\n",
    "print(f\"Target miscoverage rate: {alpha} (90% coverage)\")\n",
    "\n",
    "# Create LABEL predictor\n",
    "label_predictor = LABEL(model=model, alpha=alpha)\n",
    "\n",
    "# Calibrate on calibration set\n",
    "print(\"Calibrating LABEL predictor...\")\n",
    "label_predictor.calibrate(cal_dataset=cal_data)\n",
    "\n",
    "# Evaluate on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43447806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating LABEL predictor on test set...\")\n",
    "device=\"cuda:1\"\n",
    "y_true_label, y_prob_label, _, extra_label = Trainer(device=device, model=label_predictor).inference(\n",
    "    test_loader, additional_outputs=[\"y_predset\"]\n",
    ")\n",
    "\n",
    "label_metrics = get_metrics_fn(\"multiclass\")(\n",
    "    y_true_label,\n",
    "    y_prob_label,\n",
    "    metrics=[\"accuracy\", \"miscoverage_ps\"],\n",
    "    y_predset=extra_label[\"y_predset\"],\n",
    ")\n",
    "\n",
    "# Calculate coverage and prediction set size\n",
    "predset = (\n",
    "    torch.tensor(extra_label[\"y_predset\"])\n",
    "    if isinstance(extra_label[\"y_predset\"], np.ndarray)\n",
    "    else extra_label[\"y_predset\"]\n",
    ")\n",
    "avg_set_size = predset.float().sum(dim=1).mean().item()\n",
    "\n",
    "# Extract scalar values from metrics\n",
    "miscoverage = label_metrics[\"miscoverage_ps\"]\n",
    "if isinstance(miscoverage, np.ndarray):\n",
    "    miscoverage = float(\n",
    "        miscoverage.item() if miscoverage.size == 1 else miscoverage.mean()\n",
    "    )\n",
    "else:\n",
    "    miscoverage = float(miscoverage)\n",
    "\n",
    "coverage = 1 - miscoverage\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"CONFORMAL PREDICTION RESULTS\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Target coverage:      {1-alpha:.0%}\")\n",
    "print(f\"  Empirical coverage:   {coverage:.2%}\")\n",
    "print(f\"  Empirical miscoverage:{miscoverage:.4f}\")\n",
    "print(f\"  Average set size:     {avg_set_size:.2f}\")\n",
    "print(f\"  Efficiency:           {1.0/avg_set_size:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Example Predictions with Prediction Sets\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: Example Predictions with Prediction Sets\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(5, len(y_true_label))):\n",
    "    true_class = int(y_true_label[i])\n",
    "    pred_class = int(y_prob_label[i].argmax())\n",
    "    pred_set = torch.where(predset[i])[0].cpu().numpy()\n",
    "\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  True: {id2label.get(true_class)}, Pred: {id2label.get(pred_class)}\")\n",
    "    print(f\"  Prediction set: {[id2label.get(c) for c in pred_set]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Interpretability Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: Interpretability Visualization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "single_loader = get_dataloader(test_data, batch_size=1, shuffle=False)\n",
    "n_viz = 3\n",
    "print(f\"\\nGenerating Chefer attention attribution for {n_viz} samples...\")\n",
    "\n",
    "model.eval()\n",
    "viz_samples = [batch for i, batch in enumerate(single_loader) if i < n_viz]\n",
    "\n",
    "fig, axes = plt.subplots(n_viz, 3, figsize=(15, 5 * n_viz))\n",
    "\n",
    "# Initialize Chefer interpreter (auto-detects ViT)\n",
    "chefer_gen = CheferRelevance(model)\n",
    "\n",
    "for idx, batch in enumerate(viz_samples):\n",
    "    image = batch[\"image\"]\n",
    "    true_label = batch[\"disease\"].item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "        pred_prob = output[\"y_prob\"][0]\n",
    "        pred_class = pred_prob.argmax().item()\n",
    "\n",
    "    # Get attribution map using attribute()\n",
    "    # Returns dict keyed by feature key (e.g., {\"image\": tensor})\n",
    "    # Input size is inferred automatically from image dimensions\n",
    "    result = chefer_gen.attribute(\n",
    "        interpolate=True,\n",
    "        class_index=pred_class,\n",
    "        **batch\n",
    "    )\n",
    "    attr_map = result[\"image\"]  # Keyed by task schema's feature key\n",
    "    \n",
    "    img_display, vit_attr_display, attention_overlay = visualize_image_attr(\n",
    "        image=image[0],\n",
    "        attribution=attr_map[0, 0],\n",
    "        interpolate=True,\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    ax1 = axes[idx, 0]\n",
    "    ax1.imshow(img_display, cmap='gray' if img_display.ndim == 2 else None)\n",
    "    ax1.set_title(f\"Original\\nTrue: {id2label.get(true_label)}\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2 = axes[idx, 1]\n",
    "    ax2.imshow(vit_attr_display, cmap='hot')\n",
    "    ax2.set_title(f\"Attribution\\nPred: {id2label.get(pred_class)}\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3 = axes[idx, 2]\n",
    "    ax3.imshow(attention_overlay)\n",
    "    ax3.set_title(f\"Overlay\\nConf: {pred_prob[pred_class]:.1%}\")\n",
    "    ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"covid19_cxr_interpretability.png\", dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved to: covid19_cxr_interpretability.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhealth312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
