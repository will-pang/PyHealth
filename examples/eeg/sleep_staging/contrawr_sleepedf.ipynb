{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62306894",
   "metadata": {},
   "source": [
    "# 1. Environment Setup\n",
    "Seed the random generators, import core dependencies, and detect the training device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ed595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pyhealth.datasets import SleepEDFDataset\n",
    "from pyhealth.datasets.splitter import split_by_sample\n",
    "from pyhealth.datasets.utils import get_dataloader\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba8ce8",
   "metadata": {},
   "source": [
    "# 2. Load Sleep-EDF Dataset\n",
    "Point to the Sleep-EDF dataset root and load the telemetry subset for sleep stage classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83784e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SleepEDFDataset(\n",
    "    root=\"../downloads/sleepedf\",  # Update this path\n",
    ")\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3085e",
   "metadata": {},
   "source": [
    "# 3. Prepare PyHealth Dataset\n",
    "Set the task for the dataset and convert raw samples into PyHealth format for self-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = dataset.set_task()\n",
    "\n",
    "print(f\"Total task samples: {len(sample_dataset)}\")\n",
    "print(f\"Input schema: {sample_dataset.input_schema}\")\n",
    "print(f\"Output schema: {sample_dataset.output_schema}\")\n",
    "\n",
    "if len(sample_dataset) == 0:\n",
    "    raise RuntimeError(\"The task did not produce any samples. Verify the dataset root.\")\n",
    "\n",
    "# Inspect a sample\n",
    "sample = sample_dataset[0]\n",
    "print(f\"\\nSample keys: {sample.keys()}\")\n",
    "print(f\"Signal shape: {sample['signal'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789868f",
   "metadata": {},
   "source": [
    "# 4. Split Dataset\n",
    "Divide the processed samples into training, validation, and test subsets before building dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34eb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds, test_ds = split_by_sample(sample_dataset, [0.7, 0.1, 0.2], seed=SEED)\n",
    "print(f\"Train/Val/Test sizes: {len(train_ds)}, {len(val_ds)}, {len(test_ds)}\")\n",
    "\n",
    "train_loader = get_dataloader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val_ds, batch_size=BATCH_SIZE) if len(val_ds) else None\n",
    "test_loader = get_dataloader(test_ds, batch_size=BATCH_SIZE) if len(test_ds) else None\n",
    "\n",
    "if len(train_loader) == 0:\n",
    "    raise RuntimeError(\"The training loader is empty. Increase the dataset size or adjust the split ratios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a3195",
   "metadata": {},
   "source": [
    "# 5. Inspect Batch Structure\n",
    "Peek at the first training batch to understand feature shapes and data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "def describe(value):\n",
    "    if hasattr(value, \"shape\"):\n",
    "        return f\"{type(value).__name__}(shape={tuple(value.shape)})\"\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        return f\"{type(value).__name__}(len={len(value)})\"\n",
    "    return type(value).__name__\n",
    "\n",
    "batch_summary = {key: describe(value) for key, value in first_batch.items()}\n",
    "print(\"Batch structure:\")\n",
    "for key, desc in batch_summary.items():\n",
    "    print(f\"  {key}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8366e",
   "metadata": {},
   "source": [
    "# 6. Instantiate ContraWR Model\n",
    "Create the PyHealth ContraWR model for self-supervised learning on sleep signals and review its parameter footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import ContraWR\n",
    "\n",
    "model = ContraWR(\n",
    "    dataset=sample_dataset,\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Feature keys: {model.feature_keys}\")\n",
    "print(f\"Label key: {model.label_keys}\")\n",
    "print(f\"Model mode: {model.mode}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35201769",
   "metadata": {},
   "source": [
    "# 7. Test Forward Pass\n",
    "Verify the model can process a batch and compute the contrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move batch to device\n",
    "test_batch = {key: value.to(device) if hasattr(value, 'to') else value \n",
    "              for key, value in first_batch.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(**test_batch)\n",
    "\n",
    "print(\"Model output keys:\", output.keys())\n",
    "if 'loss' in output:\n",
    "    print(f\"Loss value: {output['loss'].item():.4f}\")\n",
    "if 'y_prob' in output:\n",
    "    print(f\"Output probability shape: {output['y_prob'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e383f",
   "metadata": {},
   "source": [
    "# 8. Configure Trainer\n",
    "Wrap the model with the PyHealth Trainer and define optimization hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=str(device),\n",
    "    enable_logging=False,\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"epochs\": 10,\n",
    "    \"optimizer_params\": {\"lr\": 1e-3},\n",
    "    \"max_grad_norm\": 5.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b2908",
   "metadata": {},
   "source": [
    "# 9. Train the Model\n",
    "Launch the self-supervised training loop to learn representations from sleep signal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    **training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea42dbf",
   "metadata": {},
   "source": [
    "# 10. Save Model (Optional)\n",
    "Save the trained model for future use or fine-tuning on downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "save_path = \"contrawr_sleepedf_model.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': training_config,\n",
    "}, save_path)\n",
    "print(f\"Model saved to: {save_path}\")\n",
    "\n",
    "# To load the model later:\n",
    "# checkpoint = torch.load(save_path)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
