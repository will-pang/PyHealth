{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c01c70-9ac8-488b-8354-c4410458dd10",
   "metadata": {},
   "source": [
    "*Created On: Feb 10, 2026*\n",
    "## Description\n",
    "To prototype a `EHRFoundationalModelMIMIC4(BaseTask)` class, focusing first on clinical discharge notes + radiology notes pre-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b76a367-62bd-4cd6-b086-f3aa5a640a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to package root\n",
    "import os\n",
    "PROJECT_ROOT = '/Users/wpang/Desktop/PyHealth'\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# Other General Packages\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb309a7-ea3b-40fa-badb-8ac710f668a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyHealth Packages\n",
    "from pyhealth.datasets import MIMIC4Dataset\n",
    "from pyhealth.tasks import MultimodalMortalityPredictionMIMIC4\n",
    "from pyhealth.tasks.base_task import BaseTask\n",
    "\n",
    "# Will's Contribution Utilities\n",
    "from will_contribution.utils import delete_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161959c5-4626-4d48-83fc-209781adbf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "pl.Config.set_tbl_rows(1000)\n",
    "pl.Config.set_tbl_cols(100)\n",
    "pl.Config.set_fmt_str_lengths(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52a16c1-5a73-45b7-91ab-03ead81a7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "EHR_ROOT = os.path.join(PROJECT_ROOT, \"srv/local/data/physionet.org/files/mimiciv/2.2\")\n",
    "NOTE_ROOT = os.path.join(PROJECT_ROOT, \"srv/local/data/physionet.org/files/mimic-iv-note/2.2\")\n",
    "CXR_ROOT = os.path.join(PROJECT_ROOT,\"srv/local/data/physionet.org/files/mimic-cxr-jpg/2.0.0\")\n",
    "CACHE_DIR = os.path.join(PROJECT_ROOT,\"srv/local/data/wp/pyhealth_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d03709-459a-48ab-bb85-32d4a8651163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EHRFoundationalModelMIMIC4(BaseTask):\n",
    "    \n",
    "    task_name: str = \"EHRFoundationalModelMIMIC4\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the EHR Foundational Model task.\"\"\"\n",
    "        self.input_schema: Dict[str, str] = {\n",
    "            \"discharge\": \"raw\",\n",
    "            \"radiology\": \"raw\"\n",
    "        }\n",
    "        self.output_schema: Dict[str, str] = {\"mortality\": \"binary\"}\n",
    "\n",
    "    def _clean_text(self, text: Optional[str]) -> Optional[str]:\n",
    "        \"\"\"Return text if non-empty, otherwise None.\"\"\"\n",
    "        return text if text else None\n",
    "\n",
    "    def __call__(self, patient: Any) -> List[Dict[str, Any]]:\n",
    "        # Get demographic info to filter by age\n",
    "        demographics = patient.get_events(event_type=\"patients\")\n",
    "        if not demographics:\n",
    "            return []\n",
    "\n",
    "        demographics = demographics[0]\n",
    "\n",
    "        # Get visits\n",
    "        admissions = patient.get_events(event_type=\"admissions\")\n",
    "        if len(admissions) == 0:\n",
    "            return []\n",
    "\n",
    "        # Determine which admissions to process iteratively\n",
    "        # Check each admission's NEXT admission for mortality flag\n",
    "        admissions_to_process = []\n",
    "        mortality_label = 0\n",
    "\n",
    "        for i, admission in enumerate(admissions):\n",
    "            # Check if THIS admission has the death flag\n",
    "            if admission.hospital_expire_flag in [1, \"1\"]:\n",
    "                # Patient died in this admission - set mortality label\n",
    "                # but don't include this admission's data\n",
    "                mortality_label = 1\n",
    "                break\n",
    "\n",
    "            # Check if there's a next admission with death flag\n",
    "            if i + 1 < len(admissions):\n",
    "                next_admission = admissions[i + 1]\n",
    "                if next_admission.hospital_expire_flag in [1, \"1\"]:\n",
    "                    # Next admission has death - include current, set mortality\n",
    "                    admissions_to_process.append(admission)\n",
    "                    mortality_label = 1\n",
    "                    break\n",
    "\n",
    "            # No death in current or next - include this admission\n",
    "            admissions_to_process.append(admission)\n",
    "\n",
    "        if len(admissions_to_process) == 0:\n",
    "            return []\n",
    "\n",
    "        # Get first admission time as reference for lab time calculations\n",
    "        first_admission_time = admissions_to_process[0].timestamp\n",
    "\n",
    "        # Aggregated data across all admissions\n",
    "        all_discharge_notes = []  # List of individual discharge notes\n",
    "        all_radiology_notes = []  # List of individual radiology notes\n",
    "        all_discharge_notes_timestamps = [] # List of individual discharge notes timestamps\n",
    "        all_radiology_notes_timestamps = [] # List of individual discharge notes timestamps\n",
    "        discharge_note_time_diffs = []\n",
    "        radiology_notes_time_diffs = []\n",
    "        \n",
    "\n",
    "        # Process each admission and aggregate data\n",
    "        for admission in admissions_to_process:\n",
    "            # Parse admission discharge time for lab events filtering\n",
    "            try:\n",
    "                admission_dischtime = datetime.strptime(\n",
    "                    admission.dischtime, \"%Y-%m-%d %H:%M:%S\"\n",
    "                )\n",
    "            except (ValueError, AttributeError):\n",
    "                # If we can't parse discharge time, skip this admission\n",
    "                continue\n",
    "\n",
    "            # Skip if discharge is before admission (data quality issue)\n",
    "            if admission_dischtime < admission.timestamp:\n",
    "                continue\n",
    "\n",
    "            # Get notes using hadm_id filtering\n",
    "            discharge_notes = patient.get_events(\n",
    "                event_type=\"discharge\", filters=[(\"hadm_id\", \"==\", admission.hadm_id)]\n",
    "            )\n",
    "            radiology_notes = patient.get_events(\n",
    "                event_type=\"radiology\", filters=[(\"hadm_id\", \"==\", admission.hadm_id)]\n",
    "            )\n",
    "\n",
    "        # Extract and aggregate notes as individual items in lists\n",
    "            # Note: attribute is \"text\" (from mimic4_note.yaml), not \"discharge\"/\"radiology\"\n",
    "            for note in discharge_notes:\n",
    "                try:\n",
    "                    note_text = self._clean_text(note.text)\n",
    "                    if note_text:\n",
    "                        all_discharge_notes.append(note_text)\n",
    "                        all_discharge_notes_timestamps.append((note.timestamp, \"discharge\"))\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "            for note in radiology_notes:\n",
    "                try:\n",
    "                    note_text = self._clean_text(note.text)\n",
    "                    if note_text:\n",
    "                        all_radiology_notes.append(note_text)\n",
    "                        all_radiology_notes_timestamps.append((note.timestamp, \"radiology\"))\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "        # Sort discharge_notes by timestamp \n",
    "        all_discharge_notes_timestamps.sort(key=lambda x: x[0])\n",
    "        all_radiology_notes_timestamps.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Compute time difference for discharge notes (hours)\n",
    "        discharge_note_time_diffs = [0.0] + [\n",
    "            (t2[0] - t1[0]).total_seconds() / 3600\n",
    "            for t1, t2 in zip(\n",
    "                all_discharge_notes_timestamps,\n",
    "                all_discharge_notes_timestamps[1:]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Compute time difference for radiology notes (hours)\n",
    "        radiology_note_time_diffs = [0.0] + [\n",
    "            (t2[0] - t1[0]).total_seconds() / 3600\n",
    "            for t1, t2 in zip(\n",
    "                all_radiology_notes_timestamps,\n",
    "                all_radiology_notes_timestamps[1:]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"patient_id\": patient.patient_id,\n",
    "                \"discharge\": all_discharge_notes,  # List of discharge notes\n",
    "                \"discharge_note_timestamps\": [str(t) for t in all_discharge_notes_timestamps],\n",
    "                \"discharge_note_time_diffs\": [str(t) for t in discharge_note_time_diffs],\n",
    "                \"radiology\": all_radiology_notes,  # List of radiology notes\n",
    "                \"radiology_note_timestamps\": [str(t) for t in all_radiology_notes_timestamps],  \n",
    "                \"radiology_note_time_diffs\": [str(t) for t in radiology_note_time_diffs],\n",
    "                \"mortality\": mortality_label\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa71fcd-cb60-48bf-972c-25d051d8787a",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478c0656-32ab-4746-a63a-ac51325a057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_cache(CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ec8853-7deb-4610-87c2-b96cc1640e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage Starting MIMIC4Dataset init: 447.7 MB\n",
      "Initializing mimic4 dataset from /Users/wpang/Desktop/PyHealth/srv/local/data/physionet.org/files/mimiciv/2.2|/Users/wpang/Desktop/PyHealth/srv/local/data/physionet.org/files/mimic-iv-note/2.2|None (dev mode: False)\n",
      "Initializing MIMIC4EHRDataset with tables: ['diagnoses_icd', 'procedures_icd', 'prescriptions', 'labevents'] (dev mode: False)\n",
      "Using default EHR config: /Users/wpang/Desktop/PyHealth/pyhealth/datasets/configs/mimic4_ehr.yaml\n",
      "Memory usage Before initializing mimic4_ehr: 447.7 MB\n",
      "Initializing mimic4_ehr dataset from /Users/wpang/Desktop/PyHealth/srv/local/data/physionet.org/files/mimiciv/2.2 (dev mode: False)\n",
      "Memory usage After initializing mimic4_ehr: 447.9 MB\n",
      "Memory usage After EHR dataset initialization: 447.9 MB\n",
      "Initializing MIMIC4NoteDataset with tables: ['discharge', 'radiology'] (dev mode: False)\n",
      "Using default note config: /Users/wpang/Desktop/PyHealth/pyhealth/datasets/configs/mimic4_note.yaml\n",
      "Memory usage Before initializing mimic4_note: 447.9 MB\n",
      "Initializing mimic4_note dataset from /Users/wpang/Desktop/PyHealth/srv/local/data/physionet.org/files/mimic-iv-note/2.2 (dev mode: False)\n",
      "Memory usage After initializing mimic4_note: 447.9 MB\n",
      "Memory usage After Note dataset initialization: 447.9 MB\n",
      "Memory usage Completed MIMIC4Dataset init: 447.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wpang/Desktop/PyHealth/pyhealth/datasets/mimic4.py:103: UserWarning: Events from discharge table only have date timestamp (no specific time). This may affect temporal ordering of events.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = MIMIC4Dataset(\n",
    "        ehr_root=EHR_ROOT,\n",
    "        note_root=NOTE_ROOT,\n",
    "        ehr_tables=[\"diagnoses_icd\", \"procedures_icd\", \"prescriptions\", \"labevents\"],\n",
    "        note_tables=[\"discharge\", \"radiology\"],\n",
    "        cache_dir=CACHE_DIR,\n",
    "        num_workers=16\n",
    "    )\n",
    "\n",
    "# To Display:\n",
    "# dataset.global_event_df.head(10).collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bfb9ade-e2ae-4841-aa60-3096085d447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting task EHRFoundationalModelMIMIC4 for mimic4 base dataset...\n",
      "Found cached task dataframe at /Users/wpang/Desktop/PyHealth/srv/local/data/wp/pyhealth_cache/task/task_df.ld, skipping task transformation.\n",
      "Fitting processors on the dataset...\n",
      "Label mortality vocab: {0: 0, 1: 1}\n",
      "Processing samples and saving to /Users/wpang/Desktop/PyHealth/srv/local/data/wp/pyhealth_cache/task/samples_8471c6a1-17b0-529e-9819-8f26e86cf9fc.ld...\n",
      "Applying processors on data with 8 workers...\n",
      "Detected Jupyter notebook environment, setting num_workers to 1\n",
      "Single worker mode, processing sequentially\n",
      "Worker 0 started processing 176814 samples. (0 to 176814)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/176814 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['str', 'str', 'str', 'str', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'float', 'float', 'float', 'float', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'pickle', 'str', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'no_header_tensor:1']` data format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/176814 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during processor transformation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m task = EHRFoundationalModelMIMIC4()    \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Single patient\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# patient = dataset.get_patient(\"10000032\")                                                                           \u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# samples = task(patient)    \u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# All patients\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m samples = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCACHE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/task\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/pyhealth/datasets/base_dataset.py:941\u001b[39m, in \u001b[36mBaseDataset.set_task\u001b[39m\u001b[34m(self, task, num_workers, cache_dir, cache_format, input_processors, output_processors)\u001b[39m\n\u001b[32m    939\u001b[39m     \u001b[38;5;66;03m# Apply processors and save final samples to cache_dir\u001b[39;00m\n\u001b[32m    940\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing samples and saving to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msamples_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_proc_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask_df_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43msamples_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    946\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCached processed samples to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msamples_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/pyhealth/datasets/base_dataset.py:809\u001b[39m, in \u001b[36mBaseDataset._proc_transform\u001b[39m\u001b[34m(self, task_df, output_dir, num_workers)\u001b[39m\n\u001b[32m    807\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during processor transformation.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    808\u001b[39m     shutil.rmtree(output_dir)\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    811\u001b[39m     \u001b[38;5;28mself\u001b[39m.clean_tmpdir()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/pyhealth/datasets/base_dataset.py:776\u001b[39m, in \u001b[36mBaseDataset._proc_transform\u001b[39m\u001b[34m(self, task_df, output_dir, num_workers)\u001b[39m\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_workers == \u001b[32m1\u001b[39m:\n\u001b[32m    775\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mSingle worker mode, processing sequentially\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     \u001b[43m_proc_transform_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    777\u001b[39m     _litdata_merge(output_dir)\n\u001b[32m    778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/pyhealth/datasets/base_dataset.py:268\u001b[39m, in \u001b[36m_proc_transform_fn\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx):\n\u001b[32m    267\u001b[39m     transformed: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = builder.transform(dataset[i])\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m     write_index += \u001b[32m1\u001b[39m\n\u001b[32m    270\u001b[39m     complete += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/.venv/lib/python3.12/site-packages/litdata/streaming/writer.py:337\u001b[39m, in \u001b[36mBinaryWriter.add_item\u001b[39m\u001b[34m(self, index, items)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._serialized_items:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe provided index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m already exists in the cache.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m data, dim = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# Whether to encrypt the data at the sample level\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encryption \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encryption.level == EncryptionLevel.SAMPLE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/.venv/lib/python3.12/site-packages/litdata/streaming/writer.py:189\u001b[39m, in \u001b[36mBinaryWriter.serialize\u001b[39m\u001b[34m(self, items)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_spec = data_spec\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# tiny optimization to avoid looping over all the data format\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_with_data_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._item_loader.encode_data(data, sizes, flattened)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/.venv/lib/python3.12/site-packages/litdata/streaming/writer.py:213\u001b[39m, in \u001b[36mBinaryWriter._serialize_with_data_format\u001b[39m\u001b[34m(self, item, sizes, data, data_format)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m element, item_format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(item, data_format):\n\u001b[32m    212\u001b[39m     serializer = \u001b[38;5;28mself\u001b[39m._serializers_extra[item_format]\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     serialized_item, _ = \u001b[43mserializer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m     data.append(serialized_item)\n\u001b[32m    215\u001b[39m     sizes.append(serializer.size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(serializer, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(serialized_item))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PyHealth/.venv/lib/python3.12/site-packages/litdata/streaming/serializers.py:425\u001b[39m, in \u001b[36mStringSerializer.serialize\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mserialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "task = EHRFoundationalModelMIMIC4()    \n",
    "\n",
    "# Single patient\n",
    "# patient = dataset.get_patient(\"10000032\")                                                                           \n",
    "# samples = task(patient)    \n",
    "\n",
    "# All patients\n",
    "samples = dataset.set_task(task, cache_dir=f\"{CACHE_DIR}/task\", num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846a9c2-6c78-4641-9cef-13cb3dc73b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples[0].keys()\n",
    "samples[0].get('discharge_note_timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51203d31-f8f4-4288-87f7-47ce037dbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0].get('discharge_note_time_diffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01fc05-dbcf-4e89-9fca-85a2d8462983",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0].get('radiology_note_timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5547a-8ed1-4ef6-91f1-43813541a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0].get('radiology_note_time_diffs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
